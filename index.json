[{"content":"Docker telepítése Követve a hivatalos dokumentációt Raspbian esetén a convenience script segítségével telepíthetjük a Docker Engine-t.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Docker kezelése non-root felhasználóval A dcoker parancs csak root jogosúltsággal használható, azaz csak a root userrel, vagy a sudo paranccsal.\nNon-root user esetén, hogy a sudo használatát mellőzhessem ismét a hivatalos leírást követtem:\n Egy docker group létrehozása:  sudo groupadd docker A user felvétele a docker group-ba:  sudo usermod -aG docker $USER Log out és log in, hogy a group membership újra kiértékelődjön. A group paranccsal leellenőrizhetjük, hogy a user megkapta-e a docker group-ot:  groups | grep docker Hello World container futtatása A Hello World container futtatásával tesztelhetjük, hogy a Docker telepítés sikeres volt-e:\ndocker run hello-world Docker log beállítások A post-installation steps közül a logging driver beállítását találtam még hasznosnak, mert alap esetben a docker container-ek log méretének nincs határ szabva.\nAz alapértelmezett logging driver a json-file. Ha bekapcsoljuk a log rotation-t, akkor a végtelen log problémát elkerülhetjük.\nAz /etc/docker/ könyvtárba hozzunk létre egy daemon.json fájlt a következő tartalommal:\n{ \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: { \u0026#34;max-size\u0026#34;: \u0026#34;10m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;3\u0026#34; } } Így containerenként maximum 30 MB logunk lesz.\nAhhoz, hogy érvényesüljenek a beállítások újra kell indítani a Docker-t:\nsudo systemctl restart docker Ez nem egy szükséges beállítás, mert minden container esetében megadható a használni kívánt logging-driver, illetve ott azt testre is szabhatjuk.\nDocker Compose telepítése Docker Compose telepítése pip segítségével, ha nincs python3 és pip3 telepítve, akkor azokat előbb fel kell tennünk:\nsudo apt-get install -y libffi-dev libssl-dev sudo apt-get install -y python3-dev sudo apt-get install -y python3 python3-pip Majd telepíthetjük a docker-compse-t:\nsudo pip install docker-compose ","permalink":"https://thomastrinn.github.io/blog/posts/pi3-server-part-03-install-docker/","summary":"Docker telepítése Követve a hivatalos dokumentációt Raspbian esetén a convenience script segítségével telepíthetjük a Docker Engine-t.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Docker kezelése non-root felhasználóval A dcoker parancs csak root jogosúltsággal használható, azaz csak a root userrel, vagy a sudo paranccsal.\nNon-root user esetén, hogy a sudo használatát mellőzhessem ismét a hivatalos leírást követtem:\n Egy docker group létrehozása:  sudo groupadd docker A user felvétele a docker group-ba:  sudo usermod -aG docker $USER Log out és log in, hogy a group membership újra kiértékelődjön.","title":"Raspberry Pi 3 - Part 3: Install docker and docker-compose"},{"content":"Debian alapú rendszerek esetén az unattended-upgrades csomag biztosít lehetőséget update-ek automatikus futtatására.\nTelepítés sudo apt-get install unattended-upgrades apt-listchanges -y Beállítások Az unattended-upgrades beállításait az /etc/apt/apt.conf.d/50unattended-upgrades fájl tartalmazza.\nLehetőségünk van beállítani az automatikus újraindítást, ha az update után az szükséges:\nUnattended-Upgrade::Automatic-Reboot \u0026quot;true\u0026quot;; Továbbá lehetőségünk van e-mail értesítést is küldeni az alábbi két sorral:\nUnattended-Upgrade::Mail \u0026quot;user@example.com\u0026quot;; Unattended-Upgrade::MailReport \u0026quot;on-change\u0026quot;; De ez csak akkor fog működni, ha a rendszer tud e-mail-t küldeni, ehhez pedig egy olyan tool-ra van szükségünk, ami a mailx package-t támogatja.\nJelenleg úgy döntöttem e-mail küldésre nincs szükségem.\nAktiválás Az unattended-upgrades aktiválásához az alábbi parancsot futtassuk:\nsudo dpkg-reconfigure -plow unattended-upgrades Ezen parancs hatására keletkezik az /etc/apt/apt.conf.d/20auto-upgrades fájl.\nA default beállításokat meghagytam, csak kiegészítettem egy továbbival, aminek hatására 21 naponta auto clean is fut.\nAPT::Periodic::Update-Package-Lists \u0026quot;1\u0026quot;; APT::Periodic::Unattended-Upgrade \u0026quot;1\u0026quot;; APT::Periodic::AutocleanInterval \u0026quot;21\u0026quot;; További beállítási lehetőségeket az alábbi helyekről lehet kinézni:\n /etc/cron.daily/apt-compat /usr/lib/apt/apt.systemd.daily  Végül pedig dry-run módban (ami csak szimulálja a futást, de nem telepít) és debug infokkal ellátva futtassuk az unattended-upgrade-t, hogy megfelel-e elvárásainknak:\nsudo unattended-upgrade --dry-run --debug A futások logját az alábbi helyen találjuk: /var/log/unattended-upgrades/unattended-upgrades.log\n","permalink":"https://thomastrinn.github.io/blog/posts/pi3-server-part-02-auto-update/","summary":"Debian alapú rendszerek esetén az unattended-upgrades csomag biztosít lehetőséget update-ek automatikus futtatására.\nTelepítés sudo apt-get install unattended-upgrades apt-listchanges -y Beállítások Az unattended-upgrades beállításait az /etc/apt/apt.conf.d/50unattended-upgrades fájl tartalmazza.\nLehetőségünk van beállítani az automatikus újraindítást, ha az update után az szükséges:\nUnattended-Upgrade::Automatic-Reboot \u0026quot;true\u0026quot;; Továbbá lehetőségünk van e-mail értesítést is küldeni az alábbi két sorral:\nUnattended-Upgrade::Mail \u0026quot;user@example.com\u0026quot;; Unattended-Upgrade::MailReport \u0026quot;on-change\u0026quot;; De ez csak akkor fog működni, ha a rendszer tud e-mail-t küldeni, ehhez pedig egy olyan tool-ra van szükségünk, ami a mailx package-t támogatja.","title":"Raspberry Pi 3 - Part 2: Auto update"},{"content":"Az OS telepítése A célom hogy headless módon használhassam a pi-t, így nincs szükségem desktop enviromentre. Követve a hivatalos getting started leírást, az OS-t a Raspberry Pi Imager segítségével telepítem.\nMiután az SD kártyát a számítógépemhez csatlakoztattam az RP Imager-ben OS-ként nem a default beállítást választottam, hanem az other opció alatt elérhető DE nélküli változatot (ebből két verzió létezik: Lite és Full, az utóbbit választottam).\nAz Advanced Options segítségével be tudtam állítani a wifi-t, a locale beállításokat és az ssh-t.\nAz alapos előkészületeket követően, megnyomtam a WRITE gombot és némi idő elteltével be is fejeződött a telepítés.\nTelepítést követően Az SD kártyát a pi-be helyezve, majd az áram alá téve hamarosan el is volt érhető a hálózaton. Besshztam a telpítés előtti advancen options-ben beállított user és password segítsévégével.\nElső parancsommal a rendszert frissítettem:\nsudo apt update -y \u0026amp;\u0026amp; sudo apt full-upgrade -y Ennek végeztével el is kezdődhet a kaland.\n","permalink":"https://thomastrinn.github.io/blog/posts/pi3-server-part-01-setup/","summary":"Az OS telepítése A célom hogy headless módon használhassam a pi-t, így nincs szükségem desktop enviromentre. Követve a hivatalos getting started leírást, az OS-t a Raspberry Pi Imager segítségével telepítem.\nMiután az SD kártyát a számítógépemhez csatlakoztattam az RP Imager-ben OS-ként nem a default beállítást választottam, hanem az other opció alatt elérhető DE nélküli változatot (ebből két verzió létezik: Lite és Full, az utóbbit választottam).\nAz Advanced Options segítségével be tudtam állítani a wifi-t, a locale beállításokat és az ssh-t.","title":"Raspberry Pi 3 - Part 1: Setup"},{"content":"A Docker Compose egy olyan eszköz, aminek segítségével definiálni és elindítani tudunk több docker container-t.\nDocker Compose fájlok A docker-compose.yml fájl tartalmazza azon service-eket amelyeket docker container-ként akarunk futtatni.\nA .env fájl nem kötelező, de ha használjuk, akkor környezeti változókat tartalmazhat, amelyek a docker-compose.yml fájlban behivatkozhatóak. További részletek itt találhatóak.\nRendelkezésre állnak előre definiált környezeti változók, amelyekkel finomhangolhatjuk a Docker Compose működését. Az egyik ilyen környezeti változó a COMPOSE_PROJECT_NAME, amellyel a projektünk nevét adhatjuk meg, amit a docker-compose utána felhasznál prefixként a létrehozandó container-ek, volume-ok, network-ok nevéhez.\nAz elérhető környezeti változók megtalálhatóak a Compose CLI environment variables oldalon.\nDocker Compose kezelése Definíció ellenőrzése Miután elkészítettük a docker-compose.yml fájl és esetleg a .env fájl, úgy az alábbi paranccsal leellenőrizhetjük azok helyességét:\ndocker-compose config Service-k indítása docker-compose up -d A -d kapcsolóval háttérfolyamatként indítja el a service-ket.\nFutó service-ek megtekintése docker-compose ps Futó servvice-k log-jának megtekintése docker-compose logs -f A -f kapcsoló követi a log-ot.\nFutó service-ek leállítása docker-compose stop Service-k törlése docker-compose down Ha futnak a service-ek akkor azok leállításra kerülnek, majd a container-ek törlése. Ha a -v kapcsolót is megadjuk, akkor a volume-ok is törlésre kerülnek.\n","permalink":"https://thomastrinn.github.io/blog/posts/get-started-with-docker-compose/","summary":"A Docker Compose egy olyan eszköz, aminek segítségével definiálni és elindítani tudunk több docker container-t.\nDocker Compose fájlok A docker-compose.yml fájl tartalmazza azon service-eket amelyeket docker container-ként akarunk futtatni.\nA .env fájl nem kötelező, de ha használjuk, akkor környezeti változókat tartalmazhat, amelyek a docker-compose.yml fájlban behivatkozhatóak. További részletek itt találhatóak.\nRendelkezésre állnak előre definiált környezeti változók, amelyekkel finomhangolhatjuk a Docker Compose működését. Az egyik ilyen környezeti változó a COMPOSE_PROJECT_NAME, amellyel a projektünk nevét adhatjuk meg, amit a docker-compose utána felhasznál prefixként a létrehozandó container-ek, volume-ok, network-ok nevéhez.","title":"Get Started With Docker Compose"},{"content":"Az alábbi docker-compose.yml fájl egy elasticsearch és egy elastickibana service-t indít el.\nversion: \u0026#39;3\u0026#39; services: elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:7.9.3 container_name: ebla_elasticsearch environment: - xpack.security.enabled=false - discovery.type=single-node ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 cap_add: - IPC_LOCK volumes: - elasticsearch_data:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 kibana: image: docker.elastic.co/kibana/kibana:7.9.3 container_name: ebla_kibana environment: - ELASTICSEARCH_HOSTS=http://elasticsearch:9200 ports: - 5601:5601 depends_on: - elasticsearch volumes: elasticsearch_data: driver: local Ezen beállítások development környezetre ajánlatosak, production esetén ez kerülendő. További információk itt találhatóak.\n","permalink":"https://thomastrinn.github.io/blog/posts/elasticsearch-in-docker/","summary":"Az alábbi docker-compose.yml fájl egy elasticsearch és egy elastickibana service-t indít el.\nversion: \u0026#39;3\u0026#39; services: elasticsearch: image: docker.elastic.co/elasticsearch/elasticsearch:7.9.3 container_name: ebla_elasticsearch environment: - xpack.security.enabled=false - discovery.type=single-node ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 cap_add: - IPC_LOCK volumes: - elasticsearch_data:/usr/share/elasticsearch/data ports: - 9200:9200 - 9300:9300 kibana: image: docker.elastic.co/kibana/kibana:7.9.3 container_name: ebla_kibana environment: - ELASTICSEARCH_HOSTS=http://elasticsearch:9200 ports: - 5601:5601 depends_on: - elasticsearch volumes: elasticsearch_data: driver: local Ezen beállítások development környezetre ajánlatosak, production esetén ez kerülendő.","title":"Elasticsearch in Docker"},{"content":"A SonarQube egy kód minőség elemző eszköz.\nSonarQube futtatása docker-compose service-ként docker-compose.yml:\nversion: \u0026#34;3\u0026#34; services: sonarqube: image: sonarqube:8.9-community container_name: sonarqube depends_on: - db ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 environment: SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar SONAR_JDBC_USERNAME: sonar SONAR_JDBC_PASSWORD: sonar volumes: - sonarqube_data:/opt/sonarqube/data - sonarqube_extensions:/opt/sonarqube/extensions - sonarqube_logs:/opt/sonarqube/logs ports: - \u0026#34;9010:9000\u0026#34; db: image: postgres:12 container_name: sonarqube-postgres environment: POSTGRES_USER: sonar POSTGRES_PASSWORD: sonar ports: - 14432:5432 volumes: - postgresql:/var/lib/postgresql - postgresql_data:/var/lib/postgresql/data volumes: sonarqube_data: sonarqube_extensions: sonarqube_logs: postgresql: postgresql_data: SonarQube indítása: docker-compose up -d\nMivel a SonarQube embedded Elasticserch-t használ szükség lehet a host gépen a következő beállításra:\nsysctl -w vm.max_map_count=524288 Ha még így is gond volna, akkor a SonarQube Docker Hub oldalból induljál ki.\nSikeres indítás követően az alkalmazás elérhető a http://localhost:9010/ url-en.\nBelépni admin/admin segítségével lehet.\nSonar Scanner futtatása docker container-ből Ha sonar-scanner-t kell futtatnunk a projektünk forráskódján, akkor azt is megtehetjük docker container-ből, az alábbi módon:\ndocker run --rm \\  --net host \\  -v \u0026#34;$(pwd):/usr/src\u0026#34; \\  sonarsource/sonar-scanner-cli \\  -Dsonar.projectKey=\u0026lt;your-projectKey\u0026gt; \\  -Dsonar.host.url=\u0026lt;your-sonar-host\u0026gt; \\  -Dsonar.login=\u0026lt;your-login\u0026gt; A -v \u0026quot;$(pwd):/usr/src\u0026quot; azt a mapping-et mutatja, hogy ha a forráskódunk könyvtárában adjuk ki ezt a parancsot, akkor az a container /usr/src könyvtárára mutat, amelyben a sonar-scanner keresi a forráskódot.\nA -Dsonar.* paraméterek értékét meg a sonarqube oldal a project létrehozásakor megad nekünk, s azokat kell ide behelyettesítenünk.\n","permalink":"https://thomastrinn.github.io/blog/posts/sonarqube-in-docker/","summary":"A SonarQube egy kód minőség elemző eszköz.\nSonarQube futtatása docker-compose service-ként docker-compose.yml:\nversion: \u0026#34;3\u0026#34; services: sonarqube: image: sonarqube:8.9-community container_name: sonarqube depends_on: - db ulimits: memlock: soft: -1 hard: -1 nofile: soft: 65536 hard: 65536 environment: SONAR_JDBC_URL: jdbc:postgresql://db:5432/sonar SONAR_JDBC_USERNAME: sonar SONAR_JDBC_PASSWORD: sonar volumes: - sonarqube_data:/opt/sonarqube/data - sonarqube_extensions:/opt/sonarqube/extensions - sonarqube_logs:/opt/sonarqube/logs ports: - \u0026#34;9010:9000\u0026#34; db: image: postgres:12 container_name: sonarqube-postgres environment: POSTGRES_USER: sonar POSTGRES_PASSWORD: sonar ports: - 14432:5432 volumes: - postgresql:/var/lib/postgresql - postgresql_data:/var/lib/postgresql/data volumes: sonarqube_data: sonarqube_extensions: sonarqube_logs: postgresql: postgresql_data: SonarQube indítása: docker-compose up -d","title":"SonarQube in Docker"},{"content":"PostgreSQL server könnyen indítható docker container segítségével. A container létrehozását docker-compose segítségével végzem.\nPostgreSQL docker-compose service Ahhoz, hogy docker-compose segítségével hozzunk létre a postgresql docker containert két fájlra lesz szükségünk. Az egyik a .env fájl a másik a docker-compose.yml.\nA .env fájl nem kötelező, de praktikus, itt környezeti változókat definiálhatunk, amelyeket a docker-compose.yml fájlban fel tudunk használni.\nA docker-compose.yml fájlban definiáljuk a service-ket a volumes-eket. Jelen esetben csak egy service-t definiálunk, a postgresql-t.\nA .env fájl tartalma:\nCOMPOSE_PROJECT_NAME=postgres POSTGRES_PASSWORD=postgres POSTGRES_USER=postgres POSTGRES_DB=postgres A COMPOSE_PROJECT_NAME környezeti változóval a project nevét adhatjuk meg, részleteket itt olvashatunk.\nA többi környezeti változót pedig a postgresql service fogja felhasználni.\nA docker-compose.yml fájl tartalma:\nversion: \u0026#39;3.8\u0026#39; services: postgres: image: postgres:12 container_name: postgres environment: - POSTGRES_USER=${POSTGRES_USER} - POSTGRES_PASSWORD=${POSTGRES_PASSWORD} - POSTGRES_DB=${POSTGRES_DB} command: postgres -c max_connections=150 volumes: - postgres:/var/lib/postgresql/data ports: - 5432:5432 volumes: postgres: driver: local A .env-ben definiált környezeti változókat itt az enviroment: szakaszban használjuk fel, adjuk át a container-nek induláskor.\nEgy postgres nevű volume-ot definiálunk, ami a container-ben levő /var/lib/postgresql/data könyvtárra mutat. Így azét érjük el, hogy a container törlése után a postgres adatok megmaradnak és a container újra létrehozását követően meglesznek az adatbázis adatok.\nA container-ben futó postgre adatbázis beállítását a command: résznél végezhetjük el, a postgres -c \u0026lt;param1=value1\u0026gt; -c \u0026lt;param2=value2\u0026gt; parancsot megadva. A fenti esetben a max_connections értékét adjuk meg (alap értéke 100).\nKiterjedtebb leírást a postgres dockerhub oldalon találunk.\nPostgreSQL tuning Egy adott környezetre a beállítások testreszabása érdekében a következő két forrást tudom javasolni:\n Tuning your PostgreSQL Server: részletes leírása az egyes beállításoknak PGTune: egyszerű eszköz amivel könnyedén előállíthatjuk a config értékeket.  ","permalink":"https://thomastrinn.github.io/blog/posts/postgresql-in-docker/","summary":"PostgreSQL server könnyen indítható docker container segítségével. A container létrehozását docker-compose segítségével végzem.\nPostgreSQL docker-compose service Ahhoz, hogy docker-compose segítségével hozzunk létre a postgresql docker containert két fájlra lesz szükségünk. Az egyik a .env fájl a másik a docker-compose.yml.\nA .env fájl nem kötelező, de praktikus, itt környezeti változókat definiálhatunk, amelyeket a docker-compose.yml fájlban fel tudunk használni.\nA docker-compose.yml fájlban definiáljuk a service-ket a volumes-eket. Jelen esetben csak egy service-t definiálunk, a postgresql-t.","title":"PostgreSQL in Docker"},{"content":"Journal mérete A journal a /var/log/journal/ könyvtárba hozza létre a log fájlokat, amik idővel sok helyet foglalhatnak. Ennek határt szabhatunk.\nA /etc/systemd/journald.conf fájlban a SystemMaxUse változónak értéket adhatunk:\nSystemMaxUse=50M A config fájl módosítását követően a journal service-t újra kell indítanunk, hogy a változtatások érvényesüljenek:\nsystemctl restart systemd-journald Hibák megtekintése Az alábbi paranccsal a log-ban levő hibákat tekinthetjük meg:\njournalctl -r -p 3 További részletek: arch wiki journal\n","permalink":"https://thomastrinn.github.io/blog/posts/linux-systemd-journal/","summary":"Journal mérete A journal a /var/log/journal/ könyvtárba hozza létre a log fájlokat, amik idővel sok helyet foglalhatnak. Ennek határt szabhatunk.\nA /etc/systemd/journald.conf fájlban a SystemMaxUse változónak értéket adhatunk:\nSystemMaxUse=50M A config fájl módosítását követően a journal service-t újra kell indítanunk, hogy a változtatások érvényesüljenek:\nsystemctl restart systemd-journald Hibák megtekintése Az alábbi paranccsal a log-ban levő hibákat tekinthetjük meg:\njournalctl -r -p 3 További részletek: arch wiki journal","title":"Linux Systemd Journal"}]